{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Task 5 \n",
    "\n",
    "Assign:\n",
    "- engagement score to each user. \n",
    "Consider the engagement score as the Euclidean distance between the user data point & the less engaged cluster (use the first clustering for this) (Euclidean Distance)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4654c85333655407"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the data\n",
    "from src.utils import fetch_data_from_db_table\n",
    "\n",
    "df = fetch_data_from_db_table('clean_data')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T13:19:22.568123Z",
     "start_time": "2024-04-27T13:19:18.414087Z"
    }
   },
   "id": "adecf29eeac73f41",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Dur. (ms)  Avg RTT DL (ms)  Avg RTT UL (ms)  \\\n",
      "0       7.060759e-03        -0.188482    -2.279256e-01   \n",
      "1       7.060759e-03         0.731606    -2.279256e-01   \n",
      "2       7.060759e-03         0.000000    -4.744955e-16   \n",
      "3       7.060759e-03         0.000000    -4.744955e-16   \n",
      "4       7.060759e-03         0.000000    -4.744955e-16   \n",
      "...              ...              ...              ...   \n",
      "149996 -9.072880e-02        -0.756899    -2.142365e+00   \n",
      "149997  2.062895e-01        -1.109733    -9.685318e-01   \n",
      "149998  2.107973e-01        -0.139113    -6.322041e-02   \n",
      "149999  2.053184e-01        -0.453938    -2.279256e-01   \n",
      "150000  2.815807e-15         0.000000    -4.744955e-16   \n",
      "\n",
      "        Avg Bearer TP DL (kbps)  Avg Bearer TP UL (kbps)  cluster  \\\n",
      "0                     -0.960585                -0.733343        0   \n",
      "1                     -1.068281                -0.979640        0   \n",
      "2                     -1.345392                -1.458541        0   \n",
      "3                     -0.764265                -0.733343        0   \n",
      "4                     -1.345392                -1.458541        0   \n",
      "...                         ...                      ...      ...   \n",
      "149996                -0.713163                -0.548681        0   \n",
      "149997                -0.960585                -0.636588        0   \n",
      "149998                -0.771284                -0.702225        0   \n",
      "149999                -0.842753                -0.814864        0   \n",
      "150000                 0.000000                 0.000000        0   \n",
      "\n",
      "        engagement_score  \n",
      "0               0.484878  \n",
      "1               1.208938  \n",
      "2               1.130408  \n",
      "3               0.676883  \n",
      "4               1.130408  \n",
      "...                  ...  \n",
      "149996          1.808016  \n",
      "149997          0.959648  \n",
      "149998          0.472522  \n",
      "149999          0.320074  \n",
      "150000          1.281167  \n",
      "\n",
      "[150001 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Select only the columns with experience metrics\n",
    "experience_metrics = ['Dur. (ms)', 'Avg RTT DL (ms)', 'Avg RTT UL (ms)', 'Avg Bearer TP DL (kbps)', 'Avg Bearer TP UL (kbps)']\n",
    "df_experience = df[experience_metrics]\n",
    "\n",
    "# Handle missing values if any\n",
    "df_experience = df_experience.dropna()\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_experience)\n",
    "\n",
    "# Perform k-means clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "kmeans.fit(df_scaled)\n",
    "# Convert df_scaled back to a DataFrame\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=df_experience.columns)\n",
    "\n",
    "# Add the cluster labels to the original DataFrame\n",
    "df_experience['cluster'] = kmeans.labels_\n",
    "\n",
    "# Identify the less engaged cluster\n",
    "# This could be the cluster with the lowest average 'Dur. (ms)', 'Avg RTT DL (ms)', 'Avg RTT UL (ms)', 'Avg Bearer TP DL (kbps)', and 'Avg Bearer TP UL (kbps)'\n",
    "# For example, if cluster 0 is the less engaged cluster\n",
    "less_engaged_cluster = 0\n",
    "\n",
    "# Get the centroid of the less engaged cluster\n",
    "less_engaged_centroid = kmeans.cluster_centers_[less_engaged_cluster]\n",
    "\n",
    "# Calculate the Euclidean distance between each user data point and the centroid of the less engaged cluster\n",
    "df_experience['engagement_score'] = df_scaled.apply(lambda x: distance.euclidean(x, less_engaged_centroid), axis=1)\n",
    "\n",
    "# Print the DataFrame with the engagement scores\n",
    "print(df_experience)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T13:20:16.206202Z",
     "start_time": "2024-04-27T13:20:13.238534Z"
    }
   },
   "id": "4b7d5e8f8c312f25",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "405d1cb8dc04c9de"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
